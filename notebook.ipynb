{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Type, List\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", api_key=api_key)\n",
    "\n",
    "class TopicSearchToolArgsSchema(BaseModel):\n",
    "    query: str = Field(\n",
    "        description=\"The query you will search for. Example query: XZ backdoor\"\n",
    "    )\n",
    "\n",
    "class TopicSearchTool(BaseTool):\n",
    "    name: str = \"TopicSearchTool\"\n",
    "    description: str = \"\"\"\n",
    "    Use this tool to return the specified URL list.\n",
    "    It takes a query as an argument.\n",
    "    \"\"\"\n",
    "    args_schema: Type[\n",
    "        TopicSearchToolArgsSchema\n",
    "    ] = TopicSearchToolArgsSchema\n",
    "\n",
    "    def _run(self, query):\n",
    "        ddg = DuckDuckGoSearchAPIWrapper()\n",
    "        results = ddg.results(query, max_results=2)  # Retrieve up to 2 results\n",
    "        return [result['link'] for result in results]\n",
    "\n",
    "class WebScraperToolArgsSchema(BaseModel):\n",
    "    urls: List[str] = Field(description=\"List of URLs to scrape\")\n",
    "\n",
    "class WebScraperTool(BaseTool):\n",
    "    name: str = \"WebScraperTool\"\n",
    "    description: str = \"Scrape content from main tags in provided URLs.\"\n",
    "    args_schema: Type[WebScraperToolArgsSchema] = WebScraperToolArgsSchema\n",
    "    \n",
    "    def _run(self, urls):\n",
    "        all_content = []\n",
    "        for url in urls:\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                main_content = soup.find('main')\n",
    "                if main_content:\n",
    "                    all_content.append(main_content.get_text(strip=True))\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "        return all_content\n",
    "\n",
    "class ContentSaverToolArgsSchema(BaseModel):\n",
    "    content: List[str] = Field(description=\"Content to save to file\")\n",
    "    filename: str = Field(description=\"Output filename\")\n",
    "\n",
    "class ContentSaverTool(BaseTool):\n",
    "    name: str = \"ContentSaverTool\"\n",
    "    description: str = \"Save content to a text file.\"\n",
    "    args_schema: Type[ContentSaverToolArgsSchema] = ContentSaverToolArgsSchema\n",
    "    \n",
    "    def _run(self, content, filename):\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\\n\".join(content))\n",
    "        return f\"Content saved to {filename}\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    handle_parsing_errors=True,\n",
    "    tools=[\n",
    "        TopicSearchTool(),\n",
    "        WebScraperTool(),\n",
    "        ContentSaverTool()\n",
    "    ],\n",
    "    agent_kwargs={\n",
    "        \"system_message\": SystemMessage(\n",
    "            content=\"\"\"\n",
    "            You are a researcher. Follow these steps:\n",
    "\n",
    "            1. Use TopicSearchTool to find relevant URLs\n",
    "            2. Use WebScraperTool to scrape their content\n",
    "            3. Use ContentSaverTool to analyze the content and save the research about the query to a txt file\n",
    "        \"\"\"\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "query = \"Research about the XZ backdoor\"\n",
    "result = agent.invoke(query)\n",
    "print(result[\"output\"].replace(\"$\", \"\\$\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
